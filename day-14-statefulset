####in the master machine first we will create a directory which will be used as an storage for your statefulset
  sudo -i
  mkdir /pvder
  ####once you create the directory we will create Persistent Volume 
  vi pv-state.yml
  ####inside that put this file
apiVersion: v1
kind: PersistentVolume
metadata:
  name: state-pv-volume
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: local-storage
  local:
    path: /pvder
  ##by default it will look for the storage in the worker node i want to see the storage in the master node only
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In 
              values:
              - ip-172-31-85-2 ###change the host name of your master node
      ###to get the hostname 
                kubectl get nodes
###verify the pv has been created or not
kubectl apply -f pv-state.yml
 969  kubectl get pv
  970  kubectl describe pv state-pv-volume
####lets create pvc
vi state-pvc.yml
###add the below content inside the file
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: state-pv-claim
spec:
  resources:
    requests:
      storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  storageClassName: local-storage
####after saving it 
kubectl apply -f state-pvc.yml
kubectl get pvc
###first we will taint the master node
998  kubectl taint node ip-172-31-85-2 node-role.kubernetes.io/master:NoSchedule
###delete pv and pvc
kubectl delete pvc state-pv-claim
kubectl delete pv state-pv-volume
kubectl get nodes
####change the hostname to the worker node
vi pv-state.yml
######change the name to the worker node
 nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In 
              values:
              - ip-172-31-85-2 ###put the workernode hostname
####then again apply 
kubectl apply -f pv-state.yml
kubectl apply -f state-pvc.yml
######then login to the workernode machine
sudo -i
####create the same directory
mkdir /pvder
####lets deploy the statefull app
vi statefullapp.yml
######
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec:
  selector:
    app: nginx 
  ports:
  - port: 80
    name: web 
  clusterIP: None 
  selector:
    app: nginx 
--- 
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web 
spec:
  selector:
    matchLabels:
      app: nginx 
  serviceName: "nginx"
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx 
    spec:
      containers:
      - name: myapp
        image: registry.k8s.io/nginx-slim:0.8
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
      volumes: 
      - name: www
        persistentVolumeClaim:
          claimName: state-pv-claim
#####
kubectl apply -f statefullapp.yml
 1036  kubectl get statefulset
 1037  kubectl get pod
kubectl describe pod web-o
####lets test the headless service
 1032  kubectl apply -f https://k8s.io/examples/admin/dns/busybox.yaml
1035  kubectl exec -it busybox -- /bin/sh
ping web-0.nginx
###press ctrl c to exit
ping web-1.nginx
#####
exit
###we can delete some pod and see how the new pods are creating
kubectl delete pod -l app=nginx
kubectl get pod -w -l app=nginx
###verify the pod creationg on scaling
kubectl scale statefulset --replicas=5 web
kubectl get pod -w -l app-nginx
